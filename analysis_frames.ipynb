{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e204d6b0",
   "metadata": {},
   "source": [
    "# 영상 시각적 특징 분석\n",
    "\n",
    "- 1배속 영상을 넣었을 때, 모델이 1, 1.1, 1.2, 1.3 배속 중 어떤 것 같은지 판단함\n",
    "\n",
    "- Ex) 1배속 영상을 넣었는데, 1.3배속이라고 판단함 -> 이 영상의 특징은 무엇인가? (TI? SI? ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9958a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'https://www.youtube.com/watch?v=h4ILpWwU1LM'에서 30fps 비디오 스트림 URL을 가져오는 중...\n",
      "🎥 선택된 해상도: 590p @ 30fps\n",
      "URL: https://rr2---sn-n3cgv5qc5oq-bh2sy.googlevideo.com/videoplayback?expire=1752677804&ei=TGl3aNLZAcvX1d8Po5z16QI&ip=163.180.118.139&id=o-AAOdejJF_fsDo2FOGkGgcQJEHt43FMgQr456u1gUJ7uL&itag=136&aitags=133%2C134%2C135%2C136%2C160%2C242%2C243%2C244%2C247%2C278%2C298%2C299%2C302%2C303%2C308&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1752656204%2C&mh=J2&mm=31%2C26&mn=sn-n3cgv5qc5oq-bh2sy%2Csn-oguesnd6&ms=au%2Conr&mv=m&mvi=2&pl=19&rms=au%2Cau&gcr=kr&initcwndbps=5425000&bui=AY1jyLPJbY9YP5f2aFzRh271ovgSkFKdjwV_muqiokdaHRS3aE_b6bsIH62WqMghb4OyCCMBj3ZWDTyQ&vprv=1&svpuc=1&mime=video%2Fmp4&ns=BrzWowOqRKAtZfjNgC6G52cQ&rqh=1&gir=yes&clen=41029970&dur=299.566&lmt=1686381832025751&mt=1752655760&fvip=2&keepalive=yes&lmw=1&fexp=51544120&c=TVHTML5&sefc=1&txp=5432434&n=L6TFBHSMs9V4Vg&sparams=expire%2Cei%2Cip%2Cid%2Caitags%2Csource%2Crequiressl%2Cxpc%2Cgcr%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhALk-oCMREKy8x5-MA_AYSxceksz0O_t1uk80xVXYlr32AiBKDuBx5zguVzHMKn8IC8kVho_tOcDEca4EcWHCjFeEsA%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=APaTxxMwRAIgNcbnCrIzfROlmaOx5EABo7h7O6Te9hpxMe797qU5cZMCIG8K-EC9SiLYFs-QuUQXse8OXusxAUGRbvhL0w-Ea1qo\n",
      "\n",
      "🎬 시작 프레임: 3600, 종료 프레임: 3900\n",
      "🎯 프레임 간격: 1 (video fps: 30.00)\n",
      "✅ 총 300개 프레임 저장 완료. 소요 시간: 7.08초\n",
      "clip_000 저장 완료\n",
      "clip_001 저장 완료\n",
      "clip_002 저장 완료\n",
      "clip_003 저장 완료\n",
      "clip_004 저장 완료\n",
      "clip_005 저장 완료\n",
      "clip_006 저장 완료\n",
      "clip_007 저장 완료\n",
      "clip_008 저장 완료\n",
      "clip_009 저장 완료\n",
      "clip_010 저장 완료\n",
      "clip_011 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# 비디오 스트림 얻은 후 프레임 단위로 저장\n",
    "cap = utils.openVideoStream('https://www.youtube.com/watch?v=h4ILpWwU1LM')\n",
    "# utils.extractFrames720p(cap, 120, 10, 30, './frames')\n",
    "utils.extractFrames(cap, 120, 10, cap.get(cv2.CAP_PROP_FPS), './frames')\n",
    "# 프레임 저장 경로\n",
    "src_dir = './frames'\n",
    "# 24씽 나눌 클립 폴더 경로\n",
    "dst_root = './clips'\n",
    "\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "frame_files = sorted([\n",
    "    f for f in os.listdir(src_dir) if f.lower().endswith('.jpg')    \n",
    "])\n",
    "\n",
    "# 24 프레임으로 모델 학습 -> 24장씩 잘라서 저장\n",
    "clip_len = 24\n",
    "num_clips = len(frame_files) // clip_len\n",
    "\n",
    "for i in range(num_clips):\n",
    "    clip_dir = os.path.join(dst_root, f\"clip_{i:03d}\")\n",
    "    os.makedirs(clip_dir, exist_ok=True)\n",
    "\n",
    "    for j in range(clip_len):\n",
    "        frame_idx = i * clip_len + j\n",
    "        src_path = os.path.join(src_dir, frame_files[frame_idx])\n",
    "        dst_path = os.path.join(clip_dir, f\"{j:03d}.jpg\")\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    print(f\"clip_{i:03d} 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c84952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 하이퍼파라미터\n",
    "N_CLASSES = 4  # [1.0, 1.1, 1.2, 1.3]\n",
    "\n",
    "# MAC이라면 mps\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 구조 정의 (학습 때와 동일)\n",
    "model = torch.hub.load(\"facebookresearch/pytorchvideo\", \"x3d_s\", pretrained=True)\n",
    "model.blocks[-1].proj = nn.Linear(2048, N_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# 학습된 가중치 불러오기\n",
    "model.load_state_dict(torch.load(\"checkpoints/best_ep9.pth\", map_location=DEVICE))  # best_epX.pth는 저장된 파일명\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d140e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. 경로에서 프레임 이미지 리스트 얻기\n",
    "def load_img_paths(frame_dir=\"./frames\"):\n",
    "    img_paths = sorted([\n",
    "        str(Path(frame_dir) / f).replace(\"\\\\\", \"/\")\n",
    "        for f in os.listdir(frame_dir)\n",
    "        if f.lower().endswith(\".jpg\")\n",
    "    ])\n",
    "    print(f\"총 {len(img_paths)}개 프레임 로드 완료.\")\n",
    "    return img_paths\n",
    "\n",
    "# 2. 프레임들을 클립 텐서로 변환 (24프레임 기준)\n",
    "def preprocess_clip(img_paths, speed=1.0, num_frames=24, target_size=160):\n",
    "    transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((target_size, target_size)),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "\n",
    "    needed = int(num_frames * speed)\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        idx = int(round(i * speed))\n",
    "        if idx >= len(img_paths):\n",
    "            print(f\"프레임 인덱스 초과: idx={idx}, len={len(img_paths)}\")\n",
    "            return None\n",
    "        img_path = img_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"이미지 로딩 실패: {img_path}\")\n",
    "            return None\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(transform(img))\n",
    "\n",
    "    if len(frames) < num_frames:\n",
    "        print(\"프레임 수 부족\")\n",
    "        return None\n",
    "\n",
    "    clip = torch.stack(frames).permute(1, 0, 2, 3)  # (C, T, H, W)\n",
    "    return clip.unsqueeze(0)  # (1, C, T, H, W)\n",
    "\n",
    "# 3. 학습된 모델 로드\n",
    "def load_trained_model(ckpt_path=\"checkpoints/best_ep10.pth\", num_classes=4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"디바이스:\", device)\n",
    "\n",
    "    model = torch.hub.load(\"facebookresearch/pytorchvideo\", \"x3d_s\", pretrained=True)\n",
    "    model.blocks[-1].proj = torch.nn.Linear(2048, num_classes)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "# 4. 실제 예측 수행\n",
    "def predict_speed(model, device, img_paths):\n",
    "    clip_tensor = preprocess_clip(img_paths)\n",
    "    if clip_tensor is None:\n",
    "        print(\"❌ 클립 준비 실패\")\n",
    "        return\n",
    "\n",
    "    clip_tensor = clip_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(clip_tensor)\n",
    "        probs = F.softmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "    label_to_speed = {0: 1.0, 1: 1.1, 2: 1.2, 3: 1.3}\n",
    "    for idx, prob in enumerate(probs):\n",
    "        print(f\"→ {label_to_speed[idx]:.1f}x : {prob*100:.2f}%\")\n",
    "\n",
    "    pred_idx = probs.argmax()\n",
    "    pred_speed = label_to_speed[pred_idx]\n",
    "    print(f\"🎯 최종 예측된 배속: {pred_speed:.1f}x\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1e1bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 24개 프레임 로드 완료.\n",
      "디바이스: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\KHU/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 1.0x : 46.19%\n",
      "→ 1.1x : 1.69%\n",
      "→ 1.2x : 52.04%\n",
      "→ 1.3x : 0.09%\n",
      "🎯 최종 예측된 배속: 1.2x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_paths = load_img_paths(\"./clips/clip_009\")  # frames 폴더에 프레임 이미지 존재해야 함\n",
    "\n",
    "    # (2) 모델 로드\n",
    "model, device = load_trained_model(\"./best_ep9.pth\")  # 저장된 가중치 파일 경로\n",
    "\n",
    "    # (3) 예측\n",
    "predict_speed(model, device, img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1fb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
